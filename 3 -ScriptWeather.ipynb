{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtención de datos del tiempo de la web de Noaa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este notebook es obtener y procesar los datos del tiempo atmosférico de cada aeropuerto para cada vuelo.\n",
    "A continuación se irán describiendo los pasos a ejecutar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer paso es importar las librerias necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from math import cos, asin, sqrt\n",
    "import gc\n",
    "import os.path\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se lee el fichero generado anteriormente para crear nuevas columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vuelos = pd.read_csv('vuelosDeparted.csv', sep=',',low_memory=False, )\n",
    "vuelos.rename(columns={'Unnamed: 0': 'index'}, inplace=True)\n",
    "\n",
    "vuelos[\"TMIN_o\"]= ''\n",
    "vuelos[\"TMIN_d\"]= ''\n",
    "vuelos[\"TMAX_o\"]= ''\n",
    "vuelos[\"TMAX_d\"]= ''\n",
    "vuelos[\"TAVG_o\"]= ''\n",
    "vuelos[\"TAVG_d\"]= ''\n",
    "vuelos[\"SNOW_o\"]= ''\n",
    "vuelos[\"SNOW_d\"]= ''\n",
    "vuelos[\"PRCP_o\"]= ''\n",
    "vuelos[\"PRCP_d\"]= ''\n",
    "vuelos[\"SNWD_o\"]= ''\n",
    "vuelos[\"SNWD_d\"]= ''\n",
    "vuelos[\"ACMC_o\"]= ''\n",
    "vuelos[\"ACMC_d\"]= ''\n",
    "vuelos[\"ACSC_o\"]= ''\n",
    "vuelos[\"ACSC_d\"]= ''\n",
    "vuelos[\"AWDR_o\"]= ''\n",
    "vuelos[\"AWDR_d\"]= ''\n",
    "vuelos[\"AWND_o\"]= ''\n",
    "vuelos[\"AWND_d\"]= ''\n",
    "vuelos[\"EVAP_o\"]= ''\n",
    "vuelos[\"EVAP_d\"]= ''\n",
    "vuelos[\"FRTH_o\"]= ''\n",
    "vuelos[\"FRTH_d\"]= ''\n",
    "vuelos[\"TSUN_o\"]= ''\n",
    "vuelos[\"TSUN_d\"]= ''\n",
    "vuelos[\"WDMV_o\"]= ''\n",
    "vuelos[\"WDMV_d\"]= ''\n",
    "\n",
    "\n",
    "vuelos.to_csv('vuelosDatosAtmosfericos.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtienen las estaciones metereólogicas de dónde se obtendrá el tiempo.\n",
    "Hay que bajarse el siguiente fichero y renombrarlo como \"stations.txt\" :\n",
    "https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt\n",
    "\n",
    "Se puede usar el siguiente comando en entornos unix:\n",
    "!wget http://www1.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt -O stations.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL transformed to HTTPS due to an HSTS policy\n",
      "--2017-07-09 13:11:36--  https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt\n",
      "Resolving www1.ncdc.noaa.gov (www1.ncdc.noaa.gov)... 205.167.25.172, 205.167.25.171\n",
      "Connecting to www1.ncdc.noaa.gov (www1.ncdc.noaa.gov)|205.167.25.172|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8674132 (8.3M) [text/plain]\n",
      "Saving to: ‘stations.txt’\n",
      "\n",
      "stations.txt        100%[===================>]   8.27M  2.15MB/s    in 6.4s    \n",
      "\n",
      "2017-07-09 13:11:43 (1.30 MB/s) - ‘stations.txt’ saved [8674132/8674132]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www1.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt -O stations.txt\n",
    "#si fallase el comando, habria que bajarse el archivo manualmente y renombrarlo a stations.txt (sobre todo en sistemas windows)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stationstxt = \"\"\n",
    "with open(\"stations.txt\") as input:\n",
    "    stationstxt = input.read()\n",
    "    \n",
    "#Extract the data from file\n",
    "stations2 = stationstxt.split(\"\\n\")\n",
    "#Remove last line\n",
    "stations2 = stations2[:-1]\n",
    "stations2 = map(lambda line: [line[0:11],float(line[13:20]),float(line[22:30]),line[41:71]], stations2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se obtendrá los ficheros y cargará en un dataframe con la información de las estaciones y su localización.\n",
    "Además se declaran varias funciones para calcular que estación es la más cercana a cada vuelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que tener en cuenta que los ficheros de datos de Noaa tienen la información anual.\n",
    "\n",
    "\n",
    "https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/2017.csv.gz\n",
    "https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/2016.csv.gz\n",
    "https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/2015.csv.gz\n",
    "https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/2014.csv.gz\n",
    "https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/2013.csv.gz\n",
    "https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/2012.csv.gz\n",
    "https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/2011.csv.gz\n",
    "\n",
    "Por lo que hay que ir ejecutando cambiando la variable \"year\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year = '2017'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL transformed to HTTPS due to an HSTS policy\n",
      "--2017-07-09 13:17:19--  https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/2017.csv.gz\n",
      "Resolving www1.ncdc.noaa.gov (www1.ncdc.noaa.gov)... 205.167.25.172, 205.167.25.171\n",
      "Connecting to www1.ncdc.noaa.gov (www1.ncdc.noaa.gov)|205.167.25.172|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 87929815 (84M) [application/x-gzip]\n",
      "Saving to: ‘2017.csv.gz.1’\n",
      "\n",
      "2017.csv.gz.1       100%[===================>]  83.86M  5.56MB/s    in 21s     \n",
      "\n",
      "2017-07-09 13:17:41 (3.98 MB/s) - ‘2017.csv.gz.1’ saved [87929815/87929815]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "u = 'http://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/'+year+'.csv.gz'\n",
    "w = year+'.csv.gz'\n",
    "!wget $u\n",
    "!gunzip $w     \n",
    "\n",
    "#si el comando falla, recomendamos bajar manualmente el fichero de la ruta. (sobre todo en sistemas windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.8759958744\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "weatherdf = pd.read_csv(year+\".csv\",header=None)\n",
    "weatherdf.columns = [\"id\",\"date\",\"type\",\"Value1\",\"Value2\",\"Value3\",\"Value4\",\"Value5\"]\n",
    "\n",
    "##nos quedamos con las latitudes de las estaciones.\n",
    "stationsdf = pd.DataFrame(stations2)\n",
    "stationsdf.columns = [\"id\",\"lat\",\"lng\",\"name\"]\n",
    "lats = stationsdf[['lat','lng']]\n",
    "\n",
    "#funciones para calcular la distancia entre los aeropuertos y estacion metereologica mas cercana\n",
    "def distance(lat1, lon1, lat2, lon2):\n",
    "    p = 0.017453292519943295\n",
    "    a = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p)*cos(lat2*p) * (1-cos((lon2-lon1)*p)) / 2\n",
    "    return 12742 * asin(sqrt(a))\n",
    "\n",
    "def closest(data, v):\n",
    "    return min(data, key=lambda p: distance(v[0],v[1],p[0],p[1]))\n",
    "\n",
    "\n",
    "#para que la fecha no de problemas al comparar (quizas no este bien del todo)\n",
    "def tratarFecha(fecha):\n",
    "    fecha = str(fecha).split(' ')[0]\n",
    "    fecha = fecha.replace('-','')\n",
    "    fecha = int(fecha)\n",
    "    return fecha\n",
    "\n",
    "\n",
    "\n",
    "del weatherdf['Value3']\n",
    "del weatherdf['Value4']\n",
    "del weatherdf['Value5']\n",
    "del weatherdf['Value2']\n",
    "weather = weatherdf ##creamos bck\n",
    "\n",
    "\n",
    "\n",
    "def obtenerEstacion2(row):\n",
    "    lat = row['board_lat']\n",
    "    lon = row['board_lon']\n",
    "    coor = [lat,lon]\n",
    "    EMC= closest(np.asarray(lats), coor)\n",
    "    ##obtenemos el id de la estacion de board\n",
    "    aux = stationsdf[stationsdf['lat']==EMC[0]]\n",
    "    aux = stationsdf[stationsdf['lng']==EMC[1]]\n",
    "    EMC = aux['id']\n",
    "    s =EMC.to_string()\n",
    "    stationid = str(s)\n",
    "    row['stationid'] = stationid.split()[1]\n",
    "    return row\n",
    "\n",
    "def obtenerEstacion3(row):\n",
    "    lat = row['off_lat']\n",
    "    lon = row['off_lon']\n",
    "    coor = [lat,lon]\n",
    "    EMC= closest(np.asarray(lats), coor)\n",
    "    ##obtenemos el id de la estacion de board\n",
    "    aux = stationsdf[stationsdf['lat']==EMC[0]]\n",
    "    aux = stationsdf[stationsdf['lng']==EMC[1]]\n",
    "    EMC = aux['id']\n",
    "    s =EMC.to_string()\n",
    "    stationid = str(s)\n",
    "    row['stationid'] = stationid.split()[1]\n",
    "    return row\n",
    "\n",
    "def aplicarEstacionesOrigen(row):\n",
    "    row['board_stationid']= coordenadasOrigen[(coordenadasOrigen.board_lat == row['board_lat'])&(coordenadasOrigen.board_lon == row['board_lon'])]['stationid'].values[0]\n",
    "    return row\n",
    "\n",
    "def aplicarEstacionesDestino(row):\n",
    "    row['off_stationid']= coordenadasDestino[(coordenadasDestino.off_lat == row['off_lat'])&(coordenadasDestino.off_lon == row['off_lon'])]['stationid'].values[0]\n",
    "    return row\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#aplicamos y obtenemos las estaciones\n",
    "if 'board_stationid' in vuelos:\n",
    "    pass\n",
    "else:\n",
    "    coordenadasOrigen = vuelos[['board_lat','board_lon']]\n",
    "    coordenadasDestino = vuelos[['off_lat','off_lon']]\n",
    "    coordenadasOrigen = coordenadasOrigen.drop_duplicates(subset=['board_lat', 'board_lon'])\n",
    "    coordenadasDestino = coordenadasDestino.drop_duplicates(subset=['off_lat', 'off_lon'])\n",
    "    coordenadasOrigen = coordenadasOrigen.apply(lambda x:obtenerEstacion2(x),axis = 1)\n",
    "    coordenadasDestino = coordenadasDestino.apply(lambda x:obtenerEstacion3(x),axis = 1)\n",
    "    vuelos = vuelos.apply(lambda x: aplicarEstacionesOrigen(x),axis = 1)\n",
    "    vuelos = vuelos.apply(lambda x: aplicarEstacionesDestino(x),axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente función trata y junta los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tratar2(row):\n",
    "    \n",
    "    board_station = row['board_stationid']\n",
    "    off_station = row['off_stationid']\n",
    "    fecha = row['actual_time_of_departure']\n",
    "    fecha_d = row['actual_time_of_arrival'] \n",
    "    ##################################\n",
    "    #primero tratamos las fechas\n",
    "    fecha = tratarFecha(fecha)\n",
    "    fecha_d = tratarFecha(fecha_d)\n",
    "    #########################################################################################################\n",
    "    data_board = weatherdf[(weatherdf[\"id\"]==board_station)&(weatherdf['date']==fecha)].sort_values(\"date\")\n",
    "    data_off   = weatherdf[(weatherdf[\"id\"]==off_station)&(weatherdf['date']==fecha_d)].sort_values(\"date\")\n",
    "    #####################################################\n",
    "    data_board[\"Value1\"]=data_board[\"Value1\"]/10\n",
    "    data_board = data_board.reset_index()\n",
    "    data_off[\"Value1\"]=data_off[\"Value1\"]/10\n",
    "    data_off = data_off.reset_index()\n",
    "        #######################################################\n",
    "    T1 = data_board[data_board['type']=='TMIN']['Value1']\n",
    "    T2 = data_off[data_off['type']=='TMIN']['Value1']\n",
    "    T3 = data_board[data_board['type']=='TMAX']['Value1']\n",
    "    T4 = data_off[data_off['type']=='TMAX']['Value1']\n",
    "    T5 = data_board[data_board['type']=='TAVG']['Value1']\n",
    "    T6 = data_off[data_off['type']=='TAVG']['Value1']\n",
    "    T7 = data_board[data_board['type']=='SNOW']['Value1']\n",
    "    T8 = data_off[data_off['type']=='SNOW']['Value1']\n",
    "    T9 = data_board[data_board['type']=='PRCP']['Value1']\n",
    "    T10 = data_off[data_off['type']=='PRCP']['Value1']\n",
    "    T11 = data_board[data_board['type']=='SNWD']['Value1']\n",
    "    T12 = data_off[data_off['type']=='SNWD']['Value1']\n",
    "    T13 = data_board[data_board['type']=='ACMC']['Value1']\n",
    "    T14 = data_off[data_off['type']=='ACMC']['Value1']\n",
    "    T17 = data_board[data_board['type']=='ACSC']['Value1']\n",
    "    T18 = data_off[data_off['type']=='ACSC']['Value1']\n",
    "    T21 = data_board[data_board['type']=='AWDR']['Value1']\n",
    "    T22 = data_off[data_off['type']=='AWDR']['Value1']\n",
    "    T23 = data_board[data_board['type']=='AWND']['Value1']\n",
    "    T24 = data_off[data_off['type']=='AWND']['Value1']\n",
    "    T39 = data_board[data_board['type']=='EVAP']['Value1']\n",
    "    T40 = data_off[data_off['type']=='EVAP']['Value1']\n",
    "    T47 = data_board[data_board['type']=='FRTH']['Value1']\n",
    "    T48 = data_off[data_off['type']=='FRTH']['Value1']\n",
    "    T75 = data_board[data_board['type']=='TSUN']['Value1']\n",
    "    T76 = data_off[data_off['type']=='TSUN']['Value1']\n",
    "    T89 = data_board[data_board['type']=='WDMV']['Value1']\n",
    "    T90 = data_off[data_off['type']=='WDMV']['Value1']\n",
    "    \n",
    "    \n",
    "    ##############################\n",
    "    ##tratamos los valores nulos aplicando un valor nulo\n",
    "    if T1.empty:\n",
    "        T1 = 9999\n",
    "    if T2.empty:\n",
    "        T2 = 9999\n",
    "    if T3.empty:\n",
    "        T3 = 9999\n",
    "    if T4.empty:\n",
    "        T4 = 9999\n",
    "    if T5.empty:\n",
    "        T5 = 9999\n",
    "    if T6.empty:\n",
    "        T6 = 9999\n",
    "    if T7.empty:\n",
    "        T7 = 9999\n",
    "    if T8.empty:\n",
    "        T8 = 9999\n",
    "    if T9.empty:\n",
    "        T9 = 9999\n",
    "    if T10.empty:\n",
    "        T10 = 9999\n",
    "    if T11.empty:\n",
    "        T11 = 9999\n",
    "    if T12.empty:\n",
    "        T12 = 9999\n",
    "    if T13.empty:\n",
    "        T13 = 9999\n",
    "    if T14.empty:\n",
    "        T14 = 9999\n",
    "    if T17.empty:\n",
    "        T17 = 9999\n",
    "    if T18.empty:\n",
    "        T18 = 9999\n",
    "    if T21.empty:\n",
    "        T21 = 9999\n",
    "    if T22.empty:\n",
    "        T22 = 9999\n",
    "    if T23.empty:\n",
    "        T23 = 9999\n",
    "    if T24.empty:\n",
    "        T24 = 9999\n",
    "    if T39.empty:\n",
    "        T39 = 9999\n",
    "    if T40.empty:\n",
    "        T40 = 9999\n",
    "    if T47.empty:\n",
    "        T47 = 9999\n",
    "    if T48.empty:\n",
    "        T48 = 9999\n",
    "    if T75.empty:\n",
    "        T75 = 9999\n",
    "    if T76.empty:\n",
    "        T76 = 9999\n",
    "    if T89.empty:\n",
    "        T89 = 9999\n",
    "    if T90.empty:\n",
    "        T90 = 9999\n",
    "      \n",
    "        \n",
    "    #actualizamos la fila\n",
    "    row['TMIN_o']= float(T1)\n",
    "    row['TMIN_d']= float(T2)\n",
    "    row['TMAX_o']= float(T3)\n",
    "    row['TMAX_d']= float(T4)\n",
    "    row['TAVG_o']= float(T5)\n",
    "    row['TAVG_d']= float(T6)\n",
    "    row['SNOW_o']= float(T7)\n",
    "    row['SNOW_d']= float(T8)\n",
    "    row['PRCP_o']= float(T9)\n",
    "    row['PRCP_d']= float(T10)\n",
    "    row['SNWD_o']= float(T11)\n",
    "    row['SNWD_d']= float(T12)\n",
    "    row['ACMC_o']= float(T13)\n",
    "    row['ACMC_d']= float(T14)\n",
    "    row['ACSC_o']= float(T17)\n",
    "    row['ACSC_d']= float(T18)\n",
    "    row['AWDR_o']= float(T21)\n",
    "    row['AWDR_d']= float(T22)\n",
    "    row['AWND_o']= float(T23)\n",
    "    row['AWND_d']= float(T24)\n",
    "    row['EVAP_o']= float(T39)\n",
    "    row['EVAP_d']= float(T40)\n",
    "    row['FRTH_o']= float(T47)\n",
    "    row['FRTH_d']= float(T48)\n",
    "    row['TSUN_o']= float(T75)\n",
    "    row['TSUN_d']= float(T76)\n",
    "    row['WDMV_o']= float(T89)\n",
    "    row['WDMV_d']= float(T90)\n",
    "\n",
    "\n",
    "    return row\n",
    "\n",
    "def functionWeatherDay(year, month, day):\n",
    "    u = int(month+day)\n",
    "    d = int(year*10000)\n",
    "    weatherdf = weather##restauramos el bck\n",
    "    weatherdf = weatherdf[weatherdf['date']-d==u]\n",
    "    return weatherdf\n",
    "\n",
    "def functionPlus(year, month, day):    \n",
    "    start = time.time()\n",
    "    vuelosSinTratar = vuelos[vuelos['TAVG_o'].isnull()]\n",
    "    x = vuelosSinTratar[vuelosSinTratar['anyoSalida']==int(year)]\n",
    "    x = x[x['mesSalida']==month]\n",
    "    x = x[x['diaSalida']==day]\n",
    "    x = x.apply(lambda x:tratar2(x),axis = 1)\n",
    "    #para escribir ya\n",
    "    #variable auxiliar\n",
    "\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "    vuelosSinTratar['TMIN_o'] = x.set_index(['index'])['TMIN_o'].combine_first(vuelosSinTratar.set_index(['index'])['TMIN_o']).values\n",
    "    vuelosSinTratar['TMIN_d'] = x.set_index(['index'])['TMIN_d'].combine_first(vuelosSinTratar.set_index(['index'])['TMIN_d']).values\n",
    "    vuelosSinTratar['TMAX_o'] = x.set_index(['index'])['TMAX_o'].combine_first(vuelosSinTratar.set_index(['index'])['TMAX_o']).values\n",
    "    vuelosSinTratar['TMAX_d'] = x.set_index(['index'])['TMAX_d'].combine_first(vuelosSinTratar.set_index(['index'])['TMAX_d']).values\n",
    "    vuelosSinTratar['TAVG_o'] = x.set_index(['index'])['TAVG_o'].combine_first(vuelosSinTratar.set_index(['index'])['TAVG_o']).values\n",
    "    vuelosSinTratar['TAVG_d'] = x.set_index(['index'])['TAVG_d'].combine_first(vuelosSinTratar.set_index(['index'])['TAVG_d']).values\n",
    "    vuelosSinTratar['SNOW_o'] = x.set_index(['index'])['SNOW_o'].combine_first(vuelosSinTratar.set_index(['index'])['SNOW_o']).values\n",
    "    vuelosSinTratar['SNOW_d'] = x.set_index(['index'])['SNOW_d'].combine_first(vuelosSinTratar.set_index(['index'])['SNOW_d']).values\n",
    "    vuelosSinTratar['PRCP_o'] = x.set_index(['index'])['PRCP_o'].combine_first(vuelosSinTratar.set_index(['index'])['PRCP_o']).values\n",
    "    vuelosSinTratar['PRCP_d'] = x.set_index(['index'])['PRCP_d'].combine_first(vuelosSinTratar.set_index(['index'])['PRCP_d']).values\n",
    "    vuelosSinTratar['SNWD_o'] = x.set_index(['index'])['SNWD_o'].combine_first(vuelosSinTratar.set_index(['index'])['SNWD_o']).values\n",
    "    vuelosSinTratar['SNWD_d'] = x.set_index(['index'])['SNWD_d'].combine_first(vuelosSinTratar.set_index(['index'])['SNWD_d']).values\n",
    "    vuelosSinTratar['ACMC_o'] = x.set_index(['index'])['ACMC_o'].combine_first(vuelosSinTratar.set_index(['index'])['ACMC_o']).values\n",
    "    vuelosSinTratar['ACMC_d'] = x.set_index(['index'])['ACMC_d'].combine_first(vuelosSinTratar.set_index(['index'])['ACMC_d']).values\n",
    "    vuelosSinTratar['ACSC_o'] = x.set_index(['index'])['ACSC_o'].combine_first(vuelosSinTratar.set_index(['index'])['ACSC_o']).values\n",
    "    vuelosSinTratar['ACSC_d'] = x.set_index(['index'])['ACSC_d'].combine_first(vuelosSinTratar.set_index(['index'])['ACSC_d']).values\n",
    "    vuelosSinTratar['AWDR_o'] = x.set_index(['index'])['AWDR_o'].combine_first(vuelosSinTratar.set_index(['index'])['AWDR_o']).values\n",
    "    vuelosSinTratar['AWDR_d'] = x.set_index(['index'])['AWDR_d'].combine_first(vuelosSinTratar.set_index(['index'])['AWDR_d']).values\n",
    "    vuelosSinTratar['AWND_o'] = x.set_index(['index'])['AWND_o'].combine_first(vuelosSinTratar.set_index(['index'])['AWND_o']).values\n",
    "    vuelosSinTratar['AWND_d'] = x.set_index(['index'])['AWND_d'].combine_first(vuelosSinTratar.set_index(['index'])['AWND_d']).values\n",
    "    vuelosSinTratar['EVAP_o'] = x.set_index(['index'])['EVAP_o'].combine_first(vuelosSinTratar.set_index(['index'])['EVAP_o']).values\n",
    "    vuelosSinTratar['EVAP_d'] = x.set_index(['index'])['EVAP_d'].combine_first(vuelosSinTratar.set_index(['index'])['EVAP_d']).values\n",
    "    vuelosSinTratar['FRTH_o'] = x.set_index(['index'])['FRTH_o'].combine_first(vuelosSinTratar.set_index(['index'])['FRTH_o']).values\n",
    "    vuelosSinTratar['FRTH_d'] = x.set_index(['index'])['FRTH_d'].combine_first(vuelosSinTratar.set_index(['index'])['FRTH_d']).values\n",
    "    vuelosSinTratar['TSUN_o'] = x.set_index(['index'])['TSUN_o'].combine_first(vuelosSinTratar.set_index(['index'])['TSUN_o']).values\n",
    "    vuelosSinTratar['TSUN_d'] = x.set_index(['index'])['TSUN_d'].combine_first(vuelosSinTratar.set_index(['index'])['TSUN_d']).values\n",
    "    vuelosSinTratar['WDMV_o'] = x.set_index(['index'])['WDMV_o'].combine_first(vuelosSinTratar.set_index(['index'])['WDMV_o']).values\n",
    "    vuelosSinTratar['WDMV_d'] = x.set_index(['index'])['WDMV_d'].combine_first(vuelosSinTratar.set_index(['index'])['WDMV_d']).values\n",
    "\n",
    "\n",
    "    vuelos['TMIN_o'] = vuelosSinTratar.set_index(['index'])['TMIN_o'].combine_first(vuelos.set_index(['index'])['TMIN_o']).values\n",
    "    vuelos['TMIN_d'] = vuelosSinTratar.set_index(['index'])['TMIN_d'].combine_first(vuelos.set_index(['index'])['TMIN_d']).values\n",
    "    vuelos['TMAX_o'] = vuelosSinTratar.set_index(['index'])['TMAX_o'].combine_first(vuelos.set_index(['index'])['TMAX_o']).values\n",
    "    vuelos['TMAX_d'] = vuelosSinTratar.set_index(['index'])['TMAX_d'].combine_first(vuelos.set_index(['index'])['TMAX_d']).values\n",
    "    vuelos['TAVG_o'] = vuelosSinTratar.set_index(['index'])['TAVG_o'].combine_first(vuelos.set_index(['index'])['TAVG_o']).values\n",
    "    vuelos['TAVG_d'] = vuelosSinTratar.set_index(['index'])['TAVG_d'].combine_first(vuelos.set_index(['index'])['TAVG_d']).values\n",
    "    vuelos['SNOW_o'] = vuelosSinTratar.set_index(['index'])['SNOW_o'].combine_first(vuelos.set_index(['index'])['SNOW_o']).values\n",
    "    vuelos['SNOW_d'] = vuelosSinTratar.set_index(['index'])['SNOW_d'].combine_first(vuelos.set_index(['index'])['SNOW_d']).values\n",
    "    vuelos['PRCP_o'] = vuelosSinTratar.set_index(['index'])['PRCP_o'].combine_first(vuelos.set_index(['index'])['PRCP_o']).values\n",
    "    vuelos['PRCP_d'] = vuelosSinTratar.set_index(['index'])['PRCP_d'].combine_first(vuelos.set_index(['index'])['PRCP_d']).values\n",
    "    vuelos['SNWD_o'] = vuelosSinTratar.set_index(['index'])['SNWD_o'].combine_first(vuelos.set_index(['index'])['SNWD_o']).values\n",
    "    vuelos['SNWD_d'] = vuelosSinTratar.set_index(['index'])['SNWD_d'].combine_first(vuelos.set_index(['index'])['SNWD_d']).values\n",
    "    vuelos['ACMC_o'] = vuelosSinTratar.set_index(['index'])['ACMC_o'].combine_first(vuelos.set_index(['index'])['ACMC_o']).values\n",
    "    vuelos['ACMC_d'] = vuelosSinTratar.set_index(['index'])['ACMC_d'].combine_first(vuelos.set_index(['index'])['ACMC_d']).values\n",
    "    vuelos['ACSC_o'] = vuelosSinTratar.set_index(['index'])['ACSC_o'].combine_first(vuelos.set_index(['index'])['ACSC_o']).values\n",
    "    vuelos['ACSC_d'] = vuelosSinTratar.set_index(['index'])['ACSC_d'].combine_first(vuelos.set_index(['index'])['ACSC_d']).values\n",
    "    vuelos['AWDR_o'] = vuelosSinTratar.set_index(['index'])['AWDR_o'].combine_first(vuelos.set_index(['index'])['AWDR_o']).values\n",
    "    vuelos['AWDR_d'] = vuelosSinTratar.set_index(['index'])['AWDR_d'].combine_first(vuelos.set_index(['index'])['AWDR_d']).values\n",
    "    vuelos['AWND_o'] = vuelosSinTratar.set_index(['index'])['AWND_o'].combine_first(vuelos.set_index(['index'])['AWND_o']).values\n",
    "    vuelos['AWND_d'] = vuelosSinTratar.set_index(['index'])['AWND_d'].combine_first(vuelos.set_index(['index'])['AWND_d']).values\n",
    "    vuelos['EVAP_o'] = vuelosSinTratar.set_index(['index'])['EVAP_o'].combine_first(vuelos.set_index(['index'])['EVAP_o']).values\n",
    "    vuelos['EVAP_d'] = vuelosSinTratar.set_index(['index'])['EVAP_d'].combine_first(vuelos.set_index(['index'])['EVAP_d']).values\n",
    "    vuelos['FRTH_o'] = vuelosSinTratar.set_index(['index'])['FRTH_o'].combine_first(vuelos.set_index(['index'])['FRTH_o']).values\n",
    "    vuelos['FRTH_d'] = vuelosSinTratar.set_index(['index'])['FRTH_d'].combine_first(vuelos.set_index(['index'])['FRTH_d']).values\n",
    "    vuelos['TSUN_o'] = vuelosSinTratar.set_index(['index'])['TSUN_o'].combine_first(vuelos.set_index(['index'])['TSUN_o']).values\n",
    "    vuelos['TSUN_d'] = vuelosSinTratar.set_index(['index'])['TSUN_d'].combine_first(vuelos.set_index(['index'])['TSUN_d']).values\n",
    "    vuelos['WDMV_o'] = vuelosSinTratar.set_index(['index'])['WDMV_o'].combine_first(vuelos.set_index(['index'])['WDMV_o']).values\n",
    "    vuelos['WDMV_d'] = vuelosSinTratar.set_index(['index'])['WDMV_d'].combine_first(vuelos.set_index(['index'])['WDMV_d']).values\n",
    "\n",
    "    \n",
    "    #vuelos.to_csv('vuelos.csv', sep=',', index=False)\n",
    "    end = time.time()\n",
    "    print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ejecución de la siguiente celda hace que se procesen todos los vuelos de los días y meses del año.\n",
    "Recordar que hay que repetir lo mismo para cada año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#variables de inicio\n",
    "\n",
    "dia = 1\n",
    "mes = 1\n",
    "anyo = year\n",
    "for mes in range(1,13):\n",
    "    print 'empiezo el mes', mes\n",
    "    mesw = str(mes)\n",
    "    for dia in range(1,32):\n",
    "        print 'empiezo el dia - ' ,dia\n",
    "        diaw = str(dia)\n",
    "        if dia < 10:\n",
    "            diaw = '0'+diaw\n",
    "\n",
    "        weatherdf = functionWeatherDay(anyo,mesw,diaw)\n",
    "        functionPlus(year,mes,dia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vuelos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b3f767545be9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvuelos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'vuelosDatosAtmosfericos.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'vuelos' is not defined"
     ]
    }
   ],
   "source": [
    "vuelos.to_csv('vuelosDatosAtmosfericos.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto se han procesado todos los vuelos. Pero nos encontramos con el problema de tener demasiados nulos. Es decir, vuelos sin datos del tiempo. Entonces se ha decidido buscar la siguiente estación más cercana para disminuir este problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Segunda parte "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLatstation(row):\n",
    "    row['lat'] = stationsdf[stationsdf['id']==row['id']]['lat'].values[0]\n",
    "    row['lng'] = stationsdf[stationsdf['id']==row['id']]['lng'].values[0]\n",
    "    return row\n",
    "\n",
    "def obtenerEstacionBoard(row):\n",
    "    lat = row['board_lat']\n",
    "    lon = row['board_lon']\n",
    "    coor = [lat,lon]\n",
    "    EMC= closest(np.asarray(lista), coor)\n",
    "    EMC[0] = round(EMC[0],3)\n",
    "    EMC[1] = round(EMC[1],3)\n",
    "    ##obtenemos el id de la estacion de board\n",
    "    aux = stationsdf[(stationsdf.lat==EMC[0])|(stationsdf.lng==EMC[1])]\n",
    "    EMC = aux['id']\n",
    "    s = EMC.to_string()\n",
    "    stationid = str(s)\n",
    "    row['stationid'] = stationid.split()[1]\n",
    "    return row\n",
    "\n",
    "\n",
    "def aplicarEstacionesOrigen(row):\n",
    "    n = 'board_stationid_o_'+var\n",
    "    row[n] = coordenadasOrigen[(coordenadasOrigen.board_lat == row['board_lat'])&(coordenadasOrigen.board_lon == row['board_lon'])]['stationid'].values[0]\n",
    "    return row\n",
    "\n",
    "def obtenerEstacionOff(row):\n",
    "    lat = row['off_lat']\n",
    "    lon = row['off_lon']\n",
    "    coor = [lat,lon]\n",
    "    EMC= closest(np.asarray(lista), coor)\n",
    "    EMC[0] = round(EMC[0],3)\n",
    "    EMC[1] = round(EMC[1],3)\n",
    "    ##obtenemos el id de la estacion de board\n",
    "    aux = stationsdf[(stationsdf.lat==EMC[0])|(stationsdf.lng==EMC[1])]\n",
    "    EMC = aux['id']\n",
    "    s = EMC.to_string()\n",
    "    stationid = str(s)\n",
    "    row['stationid'] = stationid.split()[1]\n",
    "    return row\n",
    "\n",
    "def aplicarEstacionesDestino(row):\n",
    "    n = 'off_stationid_d_'+var\n",
    "    row[n] = coordenadasDestino[(coordenadasDestino.off_lat == row['off_lat'])&(coordenadasDestino.off_lon == row['off_lon'])]['stationid'].values[0]\n",
    "    return row\n",
    "\n",
    "def roundF(row):\n",
    "    row['lat'] = round(row['lat'],3)\n",
    "    return row\n",
    "\n",
    "def roundFF(row):\n",
    "    row['lng'] = round(row['lng'],3)\n",
    "    return row\n",
    "\n",
    "\n",
    "def obtenerDatoEstacion(row):\n",
    "    if var_.split('_')[1]=='o':\n",
    "        u = 'board_stationid_o_'+ var\n",
    "    else:\n",
    "        u = 'off_stationid_d_'+ var\n",
    "    \n",
    "    board_station = row[u]\n",
    "    fechaAux = tratarFecha(row['actual_time_of_departure'])\n",
    "    x = stationsX[stationsX.date == fechaAux]\n",
    "    if x.empty:\n",
    "        pass\n",
    "    else:\n",
    "        x= x[x.id == board_station]\n",
    "        if x.empty:\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            row[var_] = float(x.Value1.values[0])/10\n",
    "            \n",
    "    del x\n",
    "    return row\n",
    "\n",
    "def functionGest(year, month, day):\n",
    "    \n",
    "    vuelosSinTratar = vuelos[vuelos[var_]==9999.0]\n",
    "    x = vuelosSinTratar[vuelosSinTratar['anyoSalida']==year]\n",
    "    x = x[x['mesSalida']==month]\n",
    "    x = x[x['diaSalida']==day]\n",
    "    x = x.apply(lambda x:obtenerDatoEstacion(x),axis = 1)\n",
    "    pd.options.mode.chained_assignment = None\n",
    "    vuelosSinTratar[var_] = x.set_index(['index'])[var_].combine_first(vuelosSinTratar.set_index(['index'])[var_]).values\n",
    "    vuelos[var_] = vuelosSinTratar.set_index(['index'])[var_].combine_first(vuelos.set_index(['index'])[var_]).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como en pasos anteriores la siguiente celda habrá que modificarla y ejecutar los siguientes pasos varias veces. Una para cada dato a procesar.\n",
    "\n",
    "\n",
    "(Se podria montar un bucle, pero como tarda mucho, se ha particionado la ejecución)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stationstxt = \"\"\n",
    "with open(\"stations.txt\") as input:\n",
    "    stationstxt = input.read()\n",
    "\n",
    "stations2 = stationstxt.split(\"\\n\")\n",
    "stations2 = stations2[:-1]\n",
    "stations2 = map(lambda line: [line[0:11],float(line[13:20]),float(line[22:30]),line[41:71]], stations2)\n",
    "\n",
    "year = '2017'#cambiar el año para cada ciclo\n",
    "#########################  ir ejecutando de una en una para cada año\n",
    "var_ = \"PRCP_o\"   \n",
    "#var_ = \"PRCP_d\"\n",
    "#var_ = \"TAVG_o\"\n",
    "#var_ = \"TAVG_d\"\n",
    "#var_ = \"TMAX_o\"\n",
    "#var_ = \"TMAX_d\"\n",
    "#var_ = \"TMIN_o\"\n",
    "#var_ = \"TMIN_d\"\n",
    "########################\n",
    "var = var_.split(\"_\")[0]\n",
    "stationsX = weatherdf[weatherdf[\"type\"]==var]\n",
    "stationsX = stationsX.sort_values(by=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#suele tardar un poco.\n",
    "\n",
    "f = 'lista'+var+year+'.csv'\n",
    "\n",
    "if os.path.exists(f):\n",
    "    lista = pd.read_csv(f,sep = ',')\n",
    "    del lista['id']\n",
    "else:\n",
    "    lista = stationsX['id'].unique()\n",
    "    lista = pd.DataFrame(lista)\n",
    "    lista.columns = ['id']\n",
    "    lista = lista.apply(lambda x:getLatstation(x),axis=1)\n",
    "    lista.to_csv(f, sep=',', index=False)\n",
    "    del lista['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = 'board_stationid_o_'+var\n",
    "if m in vuelos:\n",
    "    pass\n",
    "else:\n",
    "    stationsdf = stationsdf.apply(lambda x: roundF(x),axis = 1)\n",
    "    stationsdf = stationsdf.apply(lambda x: roundFF(x),axis = 1)\n",
    "\n",
    "    coordenadasOrigen = vuelos[['board_lat','board_lon']]\n",
    "    coordenadasOrigen = coordenadasOrigen.drop_duplicates(subset=['board_lat', 'board_lon'])\n",
    "    coordenadasOrigen = coordenadasOrigen.apply(lambda x:obtenerEstacionBoard(x),axis = 1)\n",
    "    vuelos = vuelos.apply(lambda x: aplicarEstacionesOrigen(x),axis = 1)\n",
    "    \n",
    "vuelos.to_csv('vuelosDatosAtmosfericos.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = 'off_stationid_d_'+var\n",
    "if m in vuelos:\n",
    "    pass\n",
    "else:\n",
    "    stationsdf = stationsdf.apply(lambda x: roundF(x),axis = 1)\n",
    "    stationsdf = stationsdf.apply(lambda x: roundFF(x),axis = 1)\n",
    "\n",
    "    coordenadasDestino = vuelos[['off_lat','off_lon']]\n",
    "    coordenadasDestino = coordenadasDestino.drop_duplicates(subset=['off_lat', 'off_lon'])\n",
    "    coordenadasDestino = coordenadasDestino.apply(lambda x:obtenerEstacionOff(x),axis = 1)\n",
    "    vuelos = vuelos.apply(lambda x: aplicarEstacionesDestino(x),axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los siguientes bucles repasan día a día los vuelos del año y rellenan los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vuelos.to_csv('vuelos.csv', sep=',', index=False)\n",
    "year2 = int(year)\n",
    "for mes in range(1,13):\n",
    "    print 'empiezo el mes', mes\n",
    "    mesw = str(mes)\n",
    "    for dia in range(1,32):\n",
    "        print 'empiezo el dia - ' ,dia\n",
    "        diaw = str(dia)\n",
    "        if dia < 10:\n",
    "            diaw = '0'+diaw\n",
    "\n",
    "        functionGest(year2,mes,dia)\n",
    "        \n",
    "vuelos.to_csv('vuelosDatosAtmosfericos.csv', sep=',', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Borramos columnas que no se necesitarán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del vuelos['ACMC_o']\n",
    "del vuelos['ACMC_d']\n",
    "del vuelos['ACSC_o']\n",
    "del vuelos['ACSC_d']\n",
    "del vuelos['AWDR_o']\n",
    "del vuelos['AWDR_d']\n",
    "del vuelos['AWND_o']\n",
    "del vuelos['AWND_d']\n",
    "del vuelos['EVAP_o']\n",
    "del vuelos['EVAP_d']\n",
    "del vuelos['FRTH_o']\n",
    "del vuelos['FRTH_d']\n",
    "del vuelos['TSUN_o']\n",
    "del vuelos['TSUN_d']\n",
    "del vuelos['WDMV_o']\n",
    "del vuelos['WDMV_d']\n",
    "del vuelos['board_stationid']\n",
    "del vuelos['off_stationid']\n",
    "del vuelos['board_stationid_o_TMIN']\n",
    "del vuelos['board_stationid_o_TMAX']\n",
    "del vuelos['board_stationid_o_TAVG']\n",
    "del vuelos['board_stationid_o_PRCP']\n",
    "del vuelos['off_stationid_d_PRCP']\n",
    "del vuelos['off_stationid_d_TAVG']\n",
    "del vuelos['off_stationid_d_TMAX']\n",
    "del vuelos['off_stationid_d_TMIN']\n",
    "del vuelos['SNWD_d']\n",
    "del vuelos['SNWD_o']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dejamos a nulos lo valores no tratados o no encontrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def functionTreatNull(row):\n",
    "    \n",
    "    if row.TMIN_o == 9999.0:\n",
    "        row.TMIN_o = None\n",
    "    if row.TMIN_d == 9999.0:\n",
    "        row.TMIN_d = None\n",
    "    if row.TMAX_o == 9999.0:\n",
    "        row.TMAX_o = None\n",
    "    if row.TMAX_d == 9999.0:\n",
    "        row.TMAX_d = None\n",
    "    if row.TAVG_o == 9999.0:\n",
    "        row.TAVG_o = None\n",
    "    if row.TAVG_d == 9999.0:\n",
    "        row.TAVG_d = None\n",
    "    if row.SNOW_o == 9999.0:\n",
    "        row.SNOW_o = None\n",
    "    if row.SNOW_d == 9999.0:\n",
    "        row.SNOW_d = None\n",
    "    if row.PRCP_o == 9999.0:\n",
    "        row.PRCP_o = None\n",
    "    if row.PRCP_d == 9999.0:\n",
    "        row.PRCP_d = None\n",
    "    if row.SNWD_o == 9999.0:\n",
    "        row.SNWD_o = None\n",
    "    if row.SNWD_d == 9999.0:\n",
    "        row.SNWD_d = None\n",
    "        \n",
    "    return row\n",
    "\n",
    "vuelos = vuelos.apply(lambda x: functionTreatNull(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vuelos.to_csv('vuelosDatosAtmosfericos.csv', sep=',', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribimos los datos en un fichero csv para seguir trabajando en el siguiente paso."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
